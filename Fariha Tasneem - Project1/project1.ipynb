{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88adf8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import csv\n",
    "import json\n",
    "import sqlite3\n",
    "import os.path\n",
    "from csv import writer\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "598f277b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to convert CSV file to? (JSON or SQL)? sql\n"
     ]
    }
   ],
   "source": [
    "# User chooses output file\n",
    "userInput = input(\"What do you want to convert CSV file to? (JSON or SQL)? \")\n",
    "\n",
    "# Informative error\n",
    "if (userInput not in (\"JSON\", \"json\", \"SQL\", \"sql\")):\n",
    "    print(\"Value error: Please input JSON/json or SQL/sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b722da4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIEF SUMMARY OF DATA: \n",
      "Number of Records: 51402\n",
      "Number of Columns: 16\n"
     ]
    }
   ],
   "source": [
    "# NOTE: this function produces all the results for the project by calling\n",
    "# different functions for different benchmarks. In order to produce both the \n",
    "# JSON file and SQL file from the CSV local file, the user must input them separately \n",
    "# and run this function twice with the different file output choice. The files are \n",
    "# produced in the same folder as the code & dataset and the general summary is printed by the program\n",
    "\n",
    "# ** MY project folder has all the files (JSON file, SQL file, new file with added column) \n",
    "# because I ran everything. To replicate my results, please start out with just the data set\n",
    "# and the project1 code in the folder\n",
    "\n",
    "def all_benchmarks(csvFilePath):\n",
    "    \n",
    "    if (userInput in (\"JSON\", \"json\")):\n",
    "        # (Benchmark # 1 & 2) Call the csv_to_json function\n",
    "        #jsonFilePath = r'Full_Kaggle_Dataset.json'\n",
    "        csv_to_json(csvFilePath)\n",
    "\n",
    "    if (userInput in (\"SQL\", \"sql\")):\n",
    "        # (Benchmark # 1 & 2) Call the csv_to_sql function\n",
    "        csv_to_sql(csvFilePath)\n",
    "\n",
    "    # (Benchmark # 3 & 4) Call the add_column function\n",
    "    add_column(csvFilePath)\n",
    "\n",
    "    # (Benchmark # 5) Call generate_summary function\n",
    "    gen_summary(csvFilePath)\n",
    "\n",
    "csvFilePath = r'Full_Kaggle_Dataset.csv'\n",
    "all_benchmarks(csvFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5129e1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV --> JSON\n",
    "def csv_to_json(csvFilePath):\n",
    "    jArray = []\n",
    "     \n",
    "    # Informative error    \n",
    "    try:\n",
    "        # Ingest/read a local file that you have downloaded from somewhere (CSV format)\n",
    "        with open(csvFilePath, encoding='utf-8') as csvf: \n",
    "            # Use CSV library's dictionary reader to load CSV file data\n",
    "            csvReader = csv.DictReader(csvf) \n",
    "\n",
    "            # CSV row to python dictionary\n",
    "            for row in csvReader: \n",
    "                # Add python dictionary to json array\n",
    "                jArray.append(row)\n",
    "        \n",
    "        # Convert array to JSON String and write to file\n",
    "        with open('csv_to_json_file.json', 'w', encoding='utf-8') as jsonf: \n",
    "            jString = json.dumps(jArray, indent=4)\n",
    "            jsonf.write(jString)\n",
    "    \n",
    "    # File does not exist error\n",
    "    except FileNotFoundError:\n",
    "        print('File does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa41b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV --> SQL\n",
    "def csv_to_sql(csvFilePath):\n",
    "    data = pd.read_csv(csvFilePath)   \n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Create a connection to SQL database using SQLite \n",
    "    \n",
    "    # Informative error - Check if file already exists\n",
    "    if (os.path.exists('csv_to_sql.db')):\n",
    "        print(\"SQL File already exists\")\n",
    "    \n",
    "    conn = sqlite3.connect(\"csv_to_sql.db\")\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Converting data frame to SQL database table\n",
    "    df.to_sql(\"tablename\",conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24051883",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Modify the number of columns from the source to the destination - Adding 2 new columns by combining existing columns\n",
    "\n",
    "def add_column(csvFilePath):\n",
    "    with open(csvFilePath, newline = '') as f:\n",
    "        \n",
    "        # 4. The converted (new) file should be written to disk (local file) - New file written to 'newFile.csv'\n",
    "        \n",
    "        # Open new CSV file and write old CSV data + the 2 new columns\n",
    "        with open('newFile.csv','w', newline = '') as f2:\n",
    "            writer = csv.writer(f2)\n",
    "            rows = csv.reader(f)\n",
    "            for row in rows:\n",
    "                y=[]\n",
    "                # New columm: \"Home Team - Home Points\"\n",
    "                y.append((row[3]) + \" - \" + (row[11]))\n",
    "                # New columm: \"Away Team - Away Points\"\n",
    "                y.append((row[6]) + \" - \" + (row[12]))\n",
    "                writer.writerow(row+y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5097e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Generate a brief summary of the data file ingestion after it has processed and output it to the user\n",
    "\n",
    "def gen_summary(csvFilePath):\n",
    "    # read CSV\n",
    "    data = pd.read_csv(csvFilePath)   \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # size of rows and columns\n",
    "    rows = len(df.axes[0]) \n",
    "    cols = len(df.axes[1])\n",
    "    \n",
    "    print(\"BRIEF SUMMARY OF DATA: \")\n",
    "    print(\"Number of Records: \" + str(rows))\n",
    "    print(\"Number of Columns: \" + str(cols))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCES\n",
    "# DATASET - https://www.kaggle.com/datasets/willfitzhugh/european-soccer-data?resource=download\n",
    "# https://stackoverflow.com/questions/58580184/how-to-add-two-columns-and-update-the-csv-in-python\n",
    "# https://www.geeksforgeeks.org/convert-csv-to-json-using-python/\n",
    "# https://blog.jcharistech.com/2020/01/08/how-to-convert-json-to-sql-format-in-python/\n",
    "# https://www.pythontutorial.net/python-basics/python-check-if-file-exists/#:~:text=To%20check%20if%20a%20file%20exists%2C%20you%20pass%20the%20file,path%20standard%20library.&text=If%20the%20file%20exists%2C%20the,Otherwise%2C%20it%20returns%20False%20.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
